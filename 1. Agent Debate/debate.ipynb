{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotConfiguredException",
     "evalue": "You should config a LLM configuration first",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotConfiguredException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01masyncio\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmetagpt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[1;32m      6\u001b[0m cfg \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mConfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig/config2.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmetagpt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Action, UserRequirement\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/metagpt/config.py:287\u001b[0m\n\u001b[1;32m    283\u001b[0m         env\u001b[38;5;241m.\u001b[39mupdate({k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m i\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mstr\u001b[39m)})\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m env\n\u001b[0;32m--> 287\u001b[0m CONFIG \u001b[38;5;241m=\u001b[39m \u001b[43mConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/metagpt/utils/singleton.py:21\u001b[0m, in \u001b[0;36mSingleton.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"Call method for the singleton metaclass.\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instances:\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instances[\u001b[38;5;28mcls\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSingleton\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instances[\u001b[38;5;28mcls\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/metagpt/config.py:83\u001b[0m, in \u001b[0;36mConfig.__init__\u001b[0;34m(self, yaml_file, cost_data)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# The agent needs to be billed per user, so billing information cannot be destroyed when the session ends.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcost_manager \u001b[38;5;241m=\u001b[39m CostManager(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mjson\u001b[38;5;241m.\u001b[39mloads(cost_data)) \u001b[38;5;28;01mif\u001b[39;00m cost_data \u001b[38;5;28;01melse\u001b[39;00m CostManager()\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m global_options\u001b[38;5;241m.\u001b[39mupdate(OPTIONS\u001b[38;5;241m.\u001b[39mget())\n\u001b[1;32m     85\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfig loading done.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/metagpt/config.py:155\u001b[0m, in \u001b[0;36mConfig._update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mollama_api_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOLLAMA_API_MODEL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDISABLE_LLM_PROVIDER_CHECK\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 155\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_llm_provider_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_BASE_URL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_PROXY\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_proxy\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/metagpt/config.py:118\u001b[0m, in \u001b[0;36mConfig.get_default_llm_provider_enum\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m         provider \u001b[38;5;241m=\u001b[39m LLMProviderEnum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDEFAULT_PROVIDER)\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConfiguredException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should config a LLM configuration first\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m provider \u001b[38;5;129;01mis\u001b[39;00m LLMProviderEnum\u001b[38;5;241m.\u001b[39mGEMINI \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m require_python_version(req_version\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m)):\n\u001b[1;32m    121\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse Gemini requires Python >= 3.10\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotConfiguredException\u001b[0m: You should config a LLM configuration first"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import Any\n",
    "\n",
    "import metagpt.config as config\n",
    "\n",
    "cfg = config.Config(\"config/config2.yaml\")\n",
    "\n",
    "\n",
    "from metagpt.actions import Action, UserRequirement\n",
    "from metagpt.logs import logger\n",
    "from metagpt.roles import Role\n",
    "from metagpt.schema import Message\n",
    "from metagpt.team import Team\n",
    "\n",
    "class SpeakAloud(Action):\n",
    "    \"\"\"Action: Speak out aloud in a debate (quarrel)\"\"\"\n",
    "\n",
    "    PROMPT_TEMPLATE: str = \"\"\"\n",
    "    ## BACKGROUND\n",
    "    Suppose you are {name}, you are in a debate with {opponent_name}.\n",
    "    ## DEBATE HISTORY\n",
    "    Previous rounds:\n",
    "    {context}\n",
    "    ## YOUR TURN\n",
    "    Now it's your turn, you should closely respond to your opponent's latest argument, state your position, defend your arguments, and attack your opponent's arguments,\n",
    "    craft a strong and emotional response in 80 words, in {name}'s rhetoric and viewpoints, your will argue:\n",
    "    \"\"\"\n",
    "    name: str = \"SpeakAloud\"\n",
    "\n",
    "    async def run(self, context: str, name: str, opponent_name: str):\n",
    "        prompt = self.PROMPT_TEMPLATE.format(context=context, name=name, opponent_name=opponent_name)\n",
    "        # logger.info(prompt)\n",
    "\n",
    "        rsp = await self._aask(prompt)\n",
    "\n",
    "        return rsp\n",
    "\n",
    "\n",
    "class Debator(Role):\n",
    "    name: str = \"\"\n",
    "    profile: str = \"\"\n",
    "    opponent_name: str = \"\"\n",
    "\n",
    "    def __init__(self, **data: Any):\n",
    "        super().__init__(**data)\n",
    "        self.set_actions([SpeakAloud])\n",
    "        self._watch([UserRequirement, SpeakAloud])\n",
    "\n",
    "    async def _observe(self) -> int:\n",
    "        await super()._observe()\n",
    "        # accept messages sent (from opponent) to self, disregard own messages from the last round\n",
    "        self.rc.news = [msg for msg in self.rc.news if msg.send_to == {self.name}]\n",
    "        return len(self.rc.news)\n",
    "\n",
    "    async def _act(self) -> Message:\n",
    "        logger.info(f\"{self._setting}: to do {self.rc.todo}({self.rc.todo.name})\")\n",
    "        todo = self.rc.todo  # An instance of SpeakAloud\n",
    "\n",
    "        memories = self.get_memories()\n",
    "        context = \"\\n\".join(f\"{msg.sent_from}: {msg.content}\" for msg in memories)\n",
    "        # print(context)\n",
    "\n",
    "        rsp = await todo.run(context=context, name=self.name, opponent_name=self.opponent_name)\n",
    "\n",
    "        msg = Message(\n",
    "            content=rsp,\n",
    "            role=self.profile,\n",
    "            cause_by=type(todo),\n",
    "            sent_from=self.name,\n",
    "            send_to=self.opponent_name,\n",
    "        )\n",
    "        self.rc.memory.add(msg)\n",
    "\n",
    "        return msg\n",
    "\n",
    "\n",
    "async def debate(idea: str, investment: float = 3.0, n_round: int = 5):\n",
    "    \"\"\"Run a team of presidents and watch they quarrel. :)\"\"\"\n",
    "    Biden = Debator(name=\"Biden\", profile=\"Democrat\", opponent_name=\"Trump\")\n",
    "    Trump = Debator(name=\"Trump\", profile=\"Republican\", opponent_name=\"Biden\")\n",
    "    team = Team()\n",
    "    team.hire([Biden, Trump])\n",
    "    team.invest(investment)\n",
    "    team.run_project(idea, send_to=\"Biden\")  # send debate topic to Biden and let him speak first\n",
    "    await team.run(n_round=n_round)\n",
    "\n",
    "\n",
    "def main(idea: str, investment: float = 3.0, n_round: int = 10):\n",
    "    \"\"\"\n",
    "    :param idea: Debate topic, such as \"Topic: The U.S. should commit more in climate change fighting\"\n",
    "                 or \"Trump: Climate change is a hoax\"\n",
    "    :param investment: contribute a certain dollar amount to watch the debate\n",
    "    :param n_round: maximum rounds of the debate\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    asyncio.run(debate(idea, investment, n_round))\n",
    "\n",
    "\n",
    "main(\"dogs are all black\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<LLMProviderEnum.OPENAI: 'openai'>: False, <LLMProviderEnum.ANTHROPIC: 'anthropic'>: False, <LLMProviderEnum.ZHIPUAI: 'zhipuai'>: False, <LLMProviderEnum.FIREWORKS: 'fireworks'>: False, <LLMProviderEnum.OPEN_LLM: 'open_llm'>: False, <LLMProviderEnum.GEMINI: 'gemini'>: False, <LLMProviderEnum.METAGPT: 'metagpt'>: False, <LLMProviderEnum.AZURE_OPENAI: 'azure_openai'>: False, <LLMProviderEnum.OLLAMA: 'ollama'>: False}\n",
      "True\n"
     ]
    },
    {
     "ename": "NotConfiguredException",
     "evalue": "You should config a LLM configuration first",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotConfiguredException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmetagpt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/metagpt/config.py:289\u001b[0m\n\u001b[1;32m    285\u001b[0m         env\u001b[38;5;241m.\u001b[39mupdate({k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m i\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mstr\u001b[39m)})\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m env\n\u001b[0;32m--> 289\u001b[0m CONFIG \u001b[38;5;241m=\u001b[39m \u001b[43mConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/metagpt/utils/singleton.py:21\u001b[0m, in \u001b[0;36mSingleton.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"Call method for the singleton metaclass.\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instances:\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instances[\u001b[38;5;28mcls\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSingleton\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instances[\u001b[38;5;28mcls\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/metagpt/config.py:84\u001b[0m, in \u001b[0;36mConfig.__init__\u001b[0;34m(self, yaml_file, cost_data)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# The agent needs to be billed per user, so billing information cannot be destroyed when the session ends.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcost_manager \u001b[38;5;241m=\u001b[39m CostManager(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mjson\u001b[38;5;241m.\u001b[39mloads(cost_data)) \u001b[38;5;28;01mif\u001b[39;00m cost_data \u001b[38;5;28;01melse\u001b[39;00m CostManager()\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m global_options\u001b[38;5;241m.\u001b[39mupdate(OPTIONS\u001b[38;5;241m.\u001b[39mget())\n\u001b[1;32m     86\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfig loading done.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/metagpt/config.py:158\u001b[0m, in \u001b[0;36mConfig._update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mollama_api_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOLLAMA_API_MODEL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDISABLE_LLM_PROVIDER_CHECK\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 158\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_llm_provider_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_BASE_URL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_PROXY\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_proxy\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/metagpt/config.py:121\u001b[0m, in \u001b[0;36mConfig.get_default_llm_provider_enum\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m         provider \u001b[38;5;241m=\u001b[39m LLMProviderEnum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDEFAULT_PROVIDER)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConfiguredException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should config a LLM configuration first\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m provider \u001b[38;5;129;01mis\u001b[39;00m LLMProviderEnum\u001b[38;5;241m.\u001b[39mGEMINI \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m require_python_version(req_version\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m)):\n\u001b[1;32m    124\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse Gemini requires Python >= 3.10\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotConfiguredException\u001b[0m: You should config a LLM configuration first"
     ]
    }
   ],
   "source": [
    "import metagpt.config as config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
